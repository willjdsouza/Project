{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting Forest Cover Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aiming to predict the forest cover type (the predominant kind of tree cover) from strictly cartographic variables. The actual forest cover type for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information System data. Independent variables were  derived from data obtained from the US Geological Survey and USFS.\n",
    "\n",
    "The seven types of cover types are:\n",
    "\n",
    "1 - Spruce/Fir\n",
    "\n",
    "2 - Lodgepole Pine\n",
    "\n",
    "3 - Ponderosa Pine\n",
    "\n",
    "4 - Cottonwood/Willow\n",
    "\n",
    "5 - Aspen\n",
    "\n",
    "6 - Douglas-fir\n",
    "\n",
    "7 - Krummholz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "from extrafunctions import pipeline_fn as pfn\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points     ...      Soil_Type32  Soil_Type33  \\\n",
       "0                                6279     ...                0            0   \n",
       "1                                6225     ...                0            0   \n",
       "2                                6121     ...                0            0   \n",
       "3                                6211     ...                0            0   \n",
       "4                                6172     ...                0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0           5  \n",
       "1            0            0           5  \n",
       "2            0            0           2  \n",
       "3            0            0           2  \n",
       "4            0            0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_data = pd.read_csv('C:/Users/willjdsouza/Desktop/Work/Portfolio/covtype.csv') #importing as a dataframe\n",
    "forest_data.head(5)  #sample of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 55)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_data.shape #shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elevation                             0\n",
       "Aspect                                0\n",
       "Slope                                 0\n",
       "Horizontal_Distance_To_Hydrology      0\n",
       "Vertical_Distance_To_Hydrology        0\n",
       "Horizontal_Distance_To_Roadways       0\n",
       "Hillshade_9am                         0\n",
       "Hillshade_Noon                        0\n",
       "Hillshade_3pm                         0\n",
       "Horizontal_Distance_To_Fire_Points    0\n",
       "Wilderness_Area1                      0\n",
       "Wilderness_Area2                      0\n",
       "Wilderness_Area3                      0\n",
       "Wilderness_Area4                      0\n",
       "Soil_Type1                            0\n",
       "Soil_Type2                            0\n",
       "Soil_Type3                            0\n",
       "Soil_Type4                            0\n",
       "Soil_Type5                            0\n",
       "Soil_Type6                            0\n",
       "Soil_Type7                            0\n",
       "Soil_Type8                            0\n",
       "Soil_Type9                            0\n",
       "Soil_Type10                           0\n",
       "Soil_Type11                           0\n",
       "Soil_Type12                           0\n",
       "Soil_Type13                           0\n",
       "Soil_Type14                           0\n",
       "Soil_Type15                           0\n",
       "Soil_Type16                           0\n",
       "Soil_Type17                           0\n",
       "Soil_Type18                           0\n",
       "Soil_Type19                           0\n",
       "Soil_Type20                           0\n",
       "Soil_Type21                           0\n",
       "Soil_Type22                           0\n",
       "Soil_Type23                           0\n",
       "Soil_Type24                           0\n",
       "Soil_Type25                           0\n",
       "Soil_Type26                           0\n",
       "Soil_Type27                           0\n",
       "Soil_Type28                           0\n",
       "Soil_Type29                           0\n",
       "Soil_Type30                           0\n",
       "Soil_Type31                           0\n",
       "Soil_Type32                           0\n",
       "Soil_Type33                           0\n",
       "Soil_Type34                           0\n",
       "Soil_Type35                           0\n",
       "Soil_Type36                           0\n",
       "Soil_Type37                           0\n",
       "Soil_Type38                           0\n",
       "Soil_Type39                           0\n",
       "Soil_Type40                           0\n",
       "Cover_Type                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_data.isnull().sum() #checking if they are any null values, also you can see the features in the dataset here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some sample graphs I made with Tableau. I have just shown a few samples (for the sake of the notebook not being absurdly long) of the way I observed the data visually.\n",
    "\n",
    "One thing to note is that I am only showing one chart for Soil Type vs Cover Type. This is becuase they are actualyl 40 soil types, however, for lack of repition I have chosen to only show from Soil Type 1-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2959.365301</td>\n",
       "      <td>155.656807</td>\n",
       "      <td>14.103704</td>\n",
       "      <td>269.428217</td>\n",
       "      <td>46.418855</td>\n",
       "      <td>2350.146611</td>\n",
       "      <td>212.146049</td>\n",
       "      <td>223.318716</td>\n",
       "      <td>142.528263</td>\n",
       "      <td>1980.291226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090392</td>\n",
       "      <td>0.077716</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.026803</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>2.051471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>279.984734</td>\n",
       "      <td>111.913721</td>\n",
       "      <td>7.488242</td>\n",
       "      <td>212.549356</td>\n",
       "      <td>58.295232</td>\n",
       "      <td>1559.254870</td>\n",
       "      <td>26.769889</td>\n",
       "      <td>19.768697</td>\n",
       "      <td>38.274529</td>\n",
       "      <td>1324.195210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286743</td>\n",
       "      <td>0.267725</td>\n",
       "      <td>0.052584</td>\n",
       "      <td>0.056957</td>\n",
       "      <td>0.014310</td>\n",
       "      <td>0.022641</td>\n",
       "      <td>0.161508</td>\n",
       "      <td>0.152307</td>\n",
       "      <td>0.121791</td>\n",
       "      <td>1.396504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1859.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-173.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2809.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2996.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>1710.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3163.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>3328.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3858.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>7117.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>7173.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Elevation         Aspect          Slope  \\\n",
       "count  581012.000000  581012.000000  581012.000000   \n",
       "mean     2959.365301     155.656807      14.103704   \n",
       "std       279.984734     111.913721       7.488242   \n",
       "min      1859.000000       0.000000       0.000000   \n",
       "25%      2809.000000      58.000000       9.000000   \n",
       "50%      2996.000000     127.000000      13.000000   \n",
       "75%      3163.000000     260.000000      18.000000   \n",
       "max      3858.000000     360.000000      66.000000   \n",
       "\n",
       "       Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  \\\n",
       "count                     581012.000000                   581012.000000   \n",
       "mean                         269.428217                       46.418855   \n",
       "std                          212.549356                       58.295232   \n",
       "min                            0.000000                     -173.000000   \n",
       "25%                          108.000000                        7.000000   \n",
       "50%                          218.000000                       30.000000   \n",
       "75%                          384.000000                       69.000000   \n",
       "max                         1397.000000                      601.000000   \n",
       "\n",
       "       Horizontal_Distance_To_Roadways  Hillshade_9am  Hillshade_Noon  \\\n",
       "count                    581012.000000  581012.000000   581012.000000   \n",
       "mean                       2350.146611     212.146049      223.318716   \n",
       "std                        1559.254870      26.769889       19.768697   \n",
       "min                           0.000000       0.000000        0.000000   \n",
       "25%                        1106.000000     198.000000      213.000000   \n",
       "50%                        1997.000000     218.000000      226.000000   \n",
       "75%                        3328.000000     231.000000      237.000000   \n",
       "max                        7117.000000     254.000000      254.000000   \n",
       "\n",
       "       Hillshade_3pm  Horizontal_Distance_To_Fire_Points      ...        \\\n",
       "count  581012.000000                       581012.000000      ...         \n",
       "mean      142.528263                         1980.291226      ...         \n",
       "std        38.274529                         1324.195210      ...         \n",
       "min         0.000000                            0.000000      ...         \n",
       "25%       119.000000                         1024.000000      ...         \n",
       "50%       143.000000                         1710.000000      ...         \n",
       "75%       168.000000                         2550.000000      ...         \n",
       "max       254.000000                         7173.000000      ...         \n",
       "\n",
       "         Soil_Type32    Soil_Type33    Soil_Type34    Soil_Type35  \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean        0.090392       0.077716       0.002773       0.003255   \n",
       "std         0.286743       0.267725       0.052584       0.056957   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         Soil_Type36    Soil_Type37    Soil_Type38    Soil_Type39  \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean        0.000205       0.000513       0.026803       0.023762   \n",
       "std         0.014310       0.022641       0.161508       0.152307   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         Soil_Type40     Cover_Type  \n",
       "count  581012.000000  581012.000000  \n",
       "mean        0.015060       2.051471  \n",
       "std         0.121791       1.396504  \n",
       "min         0.000000       1.000000  \n",
       "25%         0.000000       1.000000  \n",
       "50%         0.000000       2.000000  \n",
       "75%         0.000000       2.000000  \n",
       "max         1.000000       7.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"WA.BY.CT.png\"> \n",
    "<img src=\"ST.BY.CT.png\">\n",
    "<img src=\"/willjdsouza/Projects/blob/master/CT.BY.E.PNG?raw=true\" alt=\"CT.BY.E.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From taking a look at these graphs and looking at the describe() table we can see that the cover types are somewhat unique in terms of wilderness area, soil type, and elevation. We can seethat majority of each cover type is somwhat found its own unique area.\n",
    "\n",
    "This is a great indication that a classification model may work well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train length: 464809\n",
      "X_test length: 116203\n",
      "y_train length: 464809\n",
      "y_test length: 116203\n"
     ]
    }
   ],
   "source": [
    "X = forest_data.drop('Cover_Type', axis=1) #features for training\n",
    "y = forest_data.loc[:, ['Cover_Type']] #target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test,  = train_test_split(X, y, test_size=0.2, random_state=42) #random split for train and test sets\n",
    "\n",
    "print(\"X_train length:\", len(X_train))\n",
    "print(\"X_test length:\", len(X_test))\n",
    "print(\"y_train length:\", len(y_train))\n",
    "print(\"y_test length:\", len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willjdsouza\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\willjdsouza\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Building a full pipeline for data transformation\n",
    "\n",
    "numerical_values = list(X_train[['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology',\n",
    "                     'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
    "                     'Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Horizontal_Distance_To_Fire_Points']])\n",
    "\n",
    "catergorical_values = list(X_train[['Wilderness_Area1','Wilderness_Area2','Wilderness_Area3','Wilderness_Area4','Soil_Type1',\n",
    "                                    'Soil_Type2', 'Soil_Type3','Soil_Type4','Soil_Type5','Soil_Type6','Soil_Type7','Soil_Type8',\n",
    "                                    'Soil_Type9','Soil_Type10', 'Soil_Type11','Soil_Type12','Soil_Type13','Soil_Type14',\n",
    "                                    'Soil_Type15','Soil_Type16','Soil_Type17','Soil_Type18','Soil_Type19','Soil_Type20',\n",
    "                                    'Soil_Type21','Soil_Type22','Soil_Type23','Soil_Type24','Soil_Type25','Soil_Type26',\n",
    "                                    'Soil_Type27','Soil_Type28','Soil_Type29','Soil_Type30','Soil_Type31','Soil_Type32',\n",
    "                                    'Soil_Type33','Soil_Type34','Soil_Type35','Soil_Type36','Soil_Type37','Soil_Type38',\n",
    "                                    'Soil_Type39','Soil_Type40']])\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', pfn.DataFrameSelector(numerical_values)),\n",
    "        ('std_scaler', StandardScaler()), #scaling data using a standard scaler\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', pfn.DataFrameSelector(catergorical_values)), #no need to encode variables, they are binary\n",
    "    ]) \n",
    "\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "])\n",
    "\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train) \n",
    "X_test_prepared = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Listing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the models short listed to train with default hyperparameters, I have chosen an SGD Classifier, Naive Bayes Classifier, Random Forest Classifier, and a KNN Classifer. As well, I have used TensorFlow to train a DNN in to determine if this may score better. I have chosen some linear classifiers, however they will be able to pass by a OvA strategy in order for multiclass prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willjdsouza\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy Score: 0.711464278876 SGD Precision Score: 0.753295750292\n",
      "GNB Accuracy Score: 0.0923583665549 GNB Precision Score: 0.735809940852\n",
      "RFC Accuracy Score: 0.997945392624 RFC Precision Score: 0.99795239486\n",
      "KNN Accuracy Score: 0.956244392858 KNN Precision Score: 0.956498156331\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier\n",
    "sgd = SGDClassifier()\n",
    "start_sgd = timeit.default_timer()\n",
    "sgd.fit(X_train_prepared, np.ravel(y_train))\n",
    "sgd_predicted = sgd.predict(X_train_prepared)\n",
    "stop_sgd = timeit.default_timer()\n",
    "sgd_accuracy = accuracy_score(sgd_predicted, np.ravel(y_train))\n",
    "sgd_precision = precision_score(sgd_predicted, np.ravel(y_train), average = 'weighted')\n",
    "\n",
    "\n",
    "#Nave Bayes Classifier\n",
    "gnb = GaussianNB()\n",
    "start_gnb = timeit.default_timer()\n",
    "gnb.fit(X_train_prepared, np.ravel(y_train))\n",
    "gnb_predicted = gnb.predict(X_train_prepared)\n",
    "stop_gnb = timeit.default_timer()\n",
    "gnb_accuracy = accuracy_score(gnb_predicted, np.ravel(y_train))\n",
    "gnb_precision = precision_score(gnb_predicted, np.ravel(y_train), average = 'weighted')\n",
    "\n",
    "\n",
    "#Random Forest Classifier\n",
    "rfc = RandomForestClassifier()\n",
    "start_rfc = timeit.default_timer()\n",
    "rfc.fit(X_train_prepared, np.ravel(y_train))\n",
    "rfc_predicted = rfc.predict(X_train_prepared)\n",
    "stop_rfc = timeit.default_timer()\n",
    "rfc_accuracy = accuracy_score(rfc_predicted, np.ravel(y_train))\n",
    "rfc_precision = precision_score(rfc_predicted, np.ravel(y_train), average = 'weighted')\n",
    "\n",
    "\n",
    "#Nearest Neighbors Classifier\n",
    "knn = KNeighborsClassifier()\n",
    "start_knn = timeit.default_timer()\n",
    "knn.fit(X_train_prepared, np.ravel(y_train))\n",
    "knn_predicted = knn.predict(X_train_prepared)\n",
    "stop_knn = timeit.default_timer()\n",
    "knn_accuracy = accuracy_score(knn_predicted, np.ravel(y_train))\n",
    "knn_precision = precision_score(knn_predicted, np.ravel(y_train), average = 'weighted')\n",
    "\n",
    "print(\"SGD Accuracy Score:\", sgd_accuracy, \"SGD Precision Score:\", sgd_precision)\n",
    "print(\"GNB Accuracy Score:\", gnb_accuracy, \"GNB Precision Score:\", gnb_precision)\n",
    "print(\"RFC Accuracy Score:\", rfc_accuracy, \"RFC Precision Score:\", rfc_precision)\n",
    "print(\"KNN Accuracy Score:\", knn_accuracy, \"KNN Precision Score:\", knn_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default settings, we can see that Random Forest and KNN perform very well! Without even tuning the Random Forest, we have an almost perfect accuracy and precision score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Neural Networking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the deep neural network, I have chosen two layers with 50 and 30 in teh 1st and 2nd layer. As well, I have used the Adam Optimizer to help train the network. Althought in recent news, they are some concerns with this optimizer, I found it still worked best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\WILLJD~1\\AppData\\Local\\Temp\\tmp49phijk0\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F7A4DA8F98>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\WILLJD~1\\\\AppData\\\\Local\\\\Temp\\\\tmp49phijk0'}\n"
     ]
    }
   ],
   "source": [
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train_prepared)\n",
    "\n",
    "dnn_classifer = tf.contrib.learn.DNNClassifier(hidden_units= [50,30], feature_columns=feature_cols,\n",
    "                                            optimizer=tf.train.AdamOptimizer(learning_rate=0.001),\n",
    "                                            n_classes = 8)\n",
    "                                        \n",
    "dnn_classifer = tf.contrib.learn.SKCompat(dnn_classifer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\willjdsouza\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\WILLJD~1\\AppData\\Local\\Temp\\tmp49phijk0\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.89961, step = 1\n",
      "INFO:tensorflow:global_step/sec: 796.158\n",
      "INFO:tensorflow:loss = 1.35686, step = 101 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 896.215\n",
      "INFO:tensorflow:loss = 0.936467, step = 201 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 938.315\n",
      "INFO:tensorflow:loss = 0.804001, step = 301 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 919.598\n",
      "INFO:tensorflow:loss = 0.708095, step = 401 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.633\n",
      "INFO:tensorflow:loss = 0.786937, step = 501 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 846.853\n",
      "INFO:tensorflow:loss = 0.742738, step = 601 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 972.784\n",
      "INFO:tensorflow:loss = 0.794769, step = 701 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 906.743\n",
      "INFO:tensorflow:loss = 0.643614, step = 801 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 866.051\n",
      "INFO:tensorflow:loss = 0.575718, step = 901 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 956.259\n",
      "INFO:tensorflow:loss = 0.665683, step = 1001 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 979.733\n",
      "INFO:tensorflow:loss = 0.485187, step = 1101 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 803.659\n",
      "INFO:tensorflow:loss = 0.563312, step = 1201 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 942.572\n",
      "INFO:tensorflow:loss = 0.567592, step = 1301 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 974.925\n",
      "INFO:tensorflow:loss = 0.832359, step = 1401 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 774.649\n",
      "INFO:tensorflow:loss = 0.67402, step = 1501 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 910.952\n",
      "INFO:tensorflow:loss = 0.735868, step = 1601 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.739\n",
      "INFO:tensorflow:loss = 0.462831, step = 1701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.535\n",
      "INFO:tensorflow:loss = 0.437104, step = 1801 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.397\n",
      "INFO:tensorflow:loss = 0.574161, step = 1901 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.653\n",
      "INFO:tensorflow:loss = 0.634938, step = 2001 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 851.774\n",
      "INFO:tensorflow:loss = 0.740862, step = 2101 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 1017.13\n",
      "INFO:tensorflow:loss = 0.489761, step = 2201 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 951.715\n",
      "INFO:tensorflow:loss = 0.701101, step = 2301 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 858.975\n",
      "INFO:tensorflow:loss = 0.573362, step = 2401 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 850.454\n",
      "INFO:tensorflow:loss = 0.757711, step = 2501 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 951.707\n",
      "INFO:tensorflow:loss = 0.632718, step = 2601 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.16\n",
      "INFO:tensorflow:loss = 0.830202, step = 2701 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 843.31\n",
      "INFO:tensorflow:loss = 0.677773, step = 2801 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 972.385\n",
      "INFO:tensorflow:loss = 0.554189, step = 2901 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 984.523\n",
      "INFO:tensorflow:loss = 0.408333, step = 3001 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 861.453\n",
      "INFO:tensorflow:loss = 0.429405, step = 3101 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 947.57\n",
      "INFO:tensorflow:loss = 0.448242, step = 3201 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.92\n",
      "INFO:tensorflow:loss = 0.489004, step = 3301 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 936.31\n",
      "INFO:tensorflow:loss = 0.474004, step = 3401 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.94\n",
      "INFO:tensorflow:loss = 0.560868, step = 3501 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 843.19\n",
      "INFO:tensorflow:loss = 0.605472, step = 3601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 974.948\n",
      "INFO:tensorflow:loss = 0.563038, step = 3701 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 856.762\n",
      "INFO:tensorflow:loss = 0.7206, step = 3801 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 962.52\n",
      "INFO:tensorflow:loss = 0.58626, step = 3901 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.75\n",
      "INFO:tensorflow:loss = 0.725794, step = 4001 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 989.405\n",
      "INFO:tensorflow:loss = 0.582719, step = 4101 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 947.2\n",
      "INFO:tensorflow:loss = 0.710072, step = 4201 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 982.015\n",
      "INFO:tensorflow:loss = 0.492237, step = 4301 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.571\n",
      "INFO:tensorflow:loss = 0.659938, step = 4401 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 984.532\n",
      "INFO:tensorflow:loss = 0.693078, step = 4501 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 953.247\n",
      "INFO:tensorflow:loss = 0.473255, step = 4601 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.733\n",
      "INFO:tensorflow:loss = 0.634183, step = 4701 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 951.711\n",
      "INFO:tensorflow:loss = 0.60786, step = 4801 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 843.28\n",
      "INFO:tensorflow:loss = 0.569603, step = 4901 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 955.222\n",
      "INFO:tensorflow:loss = 0.501632, step = 5001 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 916.774\n",
      "INFO:tensorflow:loss = 0.616881, step = 5101 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.962\n",
      "INFO:tensorflow:loss = 0.578273, step = 5201 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 846.85\n",
      "INFO:tensorflow:loss = 0.606055, step = 5301 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 892.153\n",
      "INFO:tensorflow:loss = 0.69024, step = 5401 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 861.296\n",
      "INFO:tensorflow:loss = 0.511453, step = 5501 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 965.5\n",
      "INFO:tensorflow:loss = 0.654629, step = 5601 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.576\n",
      "INFO:tensorflow:loss = 0.545204, step = 5701 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.547\n",
      "INFO:tensorflow:loss = 0.510773, step = 5801 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 947.221\n",
      "INFO:tensorflow:loss = 0.379584, step = 5901 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 933.917\n",
      "INFO:tensorflow:loss = 0.481433, step = 6001 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 836.222\n",
      "INFO:tensorflow:loss = 0.419698, step = 6101 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 974.884\n",
      "INFO:tensorflow:loss = 0.440522, step = 6201 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 870.036\n",
      "INFO:tensorflow:loss = 0.359173, step = 6301 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 982.388\n",
      "INFO:tensorflow:loss = 0.490942, step = 6401 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 872.748\n",
      "INFO:tensorflow:loss = 0.400176, step = 6501 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 1014.52\n",
      "INFO:tensorflow:loss = 0.653363, step = 6601 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 874.311\n",
      "INFO:tensorflow:loss = 0.364705, step = 6701 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 861.437\n",
      "INFO:tensorflow:loss = 0.66728, step = 6801 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 958.542\n",
      "INFO:tensorflow:loss = 0.485764, step = 6901 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 1014.08\n",
      "INFO:tensorflow:loss = 0.586018, step = 7001 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 822.063\n",
      "INFO:tensorflow:loss = 0.631273, step = 7101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 836.207\n",
      "INFO:tensorflow:loss = 0.417126, step = 7201 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 796.264\n",
      "INFO:tensorflow:loss = 0.395156, step = 7301 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.161\n",
      "INFO:tensorflow:loss = 0.545025, step = 7401 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 888.274\n",
      "INFO:tensorflow:loss = 0.497508, step = 7501 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 924.964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.517917, step = 7601 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 796.101\n",
      "INFO:tensorflow:loss = 0.652735, step = 7701 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 891.466\n",
      "INFO:tensorflow:loss = 0.383641, step = 7801 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 829.291\n",
      "INFO:tensorflow:loss = 0.49116, step = 7901 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 770.672\n",
      "INFO:tensorflow:loss = 0.466249, step = 8001 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.199\n",
      "INFO:tensorflow:loss = 0.55549, step = 8101 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.258\n",
      "INFO:tensorflow:loss = 0.446637, step = 8201 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.585\n",
      "INFO:tensorflow:loss = 0.386417, step = 8301 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 992.902\n",
      "INFO:tensorflow:loss = 0.505638, step = 8401 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 912.601\n",
      "INFO:tensorflow:loss = 0.458949, step = 8501 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.167\n",
      "INFO:tensorflow:loss = 0.504448, step = 8601 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 831.509\n",
      "INFO:tensorflow:loss = 0.483383, step = 8701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 927.326\n",
      "INFO:tensorflow:loss = 0.525182, step = 8801 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 776.881\n",
      "INFO:tensorflow:loss = 0.317226, step = 8901 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 719.594\n",
      "INFO:tensorflow:loss = 0.562349, step = 9001 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 929.933\n",
      "INFO:tensorflow:loss = 0.505726, step = 9101 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 881.792\n",
      "INFO:tensorflow:loss = 0.534542, step = 9201 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 879.68\n",
      "INFO:tensorflow:loss = 0.547892, step = 9301 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.231\n",
      "INFO:tensorflow:loss = 0.44321, step = 9401 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 923.792\n",
      "INFO:tensorflow:loss = 0.576167, step = 9501 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 881.023\n",
      "INFO:tensorflow:loss = 0.675031, step = 9601 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 912.601\n",
      "INFO:tensorflow:loss = 0.535549, step = 9701 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1015.74\n",
      "INFO:tensorflow:loss = 0.523167, step = 9801 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 576.736\n",
      "INFO:tensorflow:loss = 0.534171, step = 9901 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.394\n",
      "INFO:tensorflow:loss = 0.336822, step = 10001 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 751.344\n",
      "INFO:tensorflow:loss = 0.560742, step = 10101 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.841\n",
      "INFO:tensorflow:loss = 0.410624, step = 10201 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.743\n",
      "INFO:tensorflow:loss = 0.344335, step = 10301 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 571.022\n",
      "INFO:tensorflow:loss = 0.383532, step = 10401 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 584.382\n",
      "INFO:tensorflow:loss = 0.381449, step = 10501 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.599\n",
      "INFO:tensorflow:loss = 0.582967, step = 10601 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.981\n",
      "INFO:tensorflow:loss = 0.442844, step = 10701 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.156\n",
      "INFO:tensorflow:loss = 0.502628, step = 10801 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.863\n",
      "INFO:tensorflow:loss = 0.411382, step = 10901 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.527\n",
      "INFO:tensorflow:loss = 0.534447, step = 11001 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.624\n",
      "INFO:tensorflow:loss = 0.441557, step = 11101 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 575.96\n",
      "INFO:tensorflow:loss = 0.355865, step = 11201 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 786.092\n",
      "INFO:tensorflow:loss = 0.51687, step = 11301 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 585.72\n",
      "INFO:tensorflow:loss = 0.522176, step = 11401 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.312\n",
      "INFO:tensorflow:loss = 0.338864, step = 11501 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 677.439\n",
      "INFO:tensorflow:loss = 0.466606, step = 11601 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.047\n",
      "INFO:tensorflow:loss = 0.59299, step = 11701 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 569.399\n",
      "INFO:tensorflow:loss = 0.397244, step = 11801 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 559.826\n",
      "INFO:tensorflow:loss = 0.362173, step = 11901 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 587.82\n",
      "INFO:tensorflow:loss = 0.431386, step = 12001 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.715\n",
      "INFO:tensorflow:loss = 0.509444, step = 12101 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.554\n",
      "INFO:tensorflow:loss = 0.515302, step = 12201 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.088\n",
      "INFO:tensorflow:loss = 0.705907, step = 12301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 916.786\n",
      "INFO:tensorflow:loss = 0.416772, step = 12401 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.757\n",
      "INFO:tensorflow:loss = 0.47791, step = 12501 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.463\n",
      "INFO:tensorflow:loss = 0.486665, step = 12601 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.848\n",
      "INFO:tensorflow:loss = 0.610982, step = 12701 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.716\n",
      "INFO:tensorflow:loss = 0.414621, step = 12801 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 622.607\n",
      "INFO:tensorflow:loss = 0.475726, step = 12901 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 567.781\n",
      "INFO:tensorflow:loss = 0.534011, step = 13001 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 570.971\n",
      "INFO:tensorflow:loss = 0.454197, step = 13101 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 682.104\n",
      "INFO:tensorflow:loss = 0.46648, step = 13201 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.467\n",
      "INFO:tensorflow:loss = 0.577749, step = 13301 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.432\n",
      "INFO:tensorflow:loss = 0.530858, step = 13401 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 592.04\n",
      "INFO:tensorflow:loss = 0.556633, step = 13501 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 591.128\n",
      "INFO:tensorflow:loss = 0.641518, step = 13601 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.777\n",
      "INFO:tensorflow:loss = 0.508333, step = 13701 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.406\n",
      "INFO:tensorflow:loss = 0.477856, step = 13801 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.945\n",
      "INFO:tensorflow:loss = 0.633579, step = 13901 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 559.768\n",
      "INFO:tensorflow:loss = 0.542855, step = 14001 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.67\n",
      "INFO:tensorflow:loss = 0.335117, step = 14101 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 605.667\n",
      "INFO:tensorflow:loss = 0.296371, step = 14201 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.635\n",
      "INFO:tensorflow:loss = 0.415729, step = 14301 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 865.187\n",
      "INFO:tensorflow:loss = 0.54062, step = 14401 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.757\n",
      "INFO:tensorflow:loss = 0.588368, step = 14501 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.09\n",
      "INFO:tensorflow:loss = 0.491376, step = 14601 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.115\n",
      "INFO:tensorflow:loss = 0.431768, step = 14701 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 832.743\n",
      "INFO:tensorflow:loss = 0.380193, step = 14801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 878.795\n",
      "INFO:tensorflow:loss = 0.448664, step = 14901 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.806\n",
      "INFO:tensorflow:loss = 0.437862, step = 15001 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 789.83\n",
      "INFO:tensorflow:loss = 0.489745, step = 15101 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 598.31\n",
      "INFO:tensorflow:loss = 0.417043, step = 15201 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.063\n",
      "INFO:tensorflow:loss = 0.532528, step = 15301 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.89\n",
      "INFO:tensorflow:loss = 0.555262, step = 15401 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.024\n",
      "INFO:tensorflow:loss = 0.632102, step = 15501 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.467\n",
      "INFO:tensorflow:loss = 0.568694, step = 15601 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 1014.41\n",
      "INFO:tensorflow:loss = 0.518602, step = 15701 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 994.33\n",
      "INFO:tensorflow:loss = 0.496862, step = 15801 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 834.471\n",
      "INFO:tensorflow:loss = 0.3015, step = 15901 (0.120 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 616.848\n",
      "INFO:tensorflow:loss = 0.387908, step = 16001 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.088\n",
      "INFO:tensorflow:loss = 0.820406, step = 16101 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.143\n",
      "INFO:tensorflow:loss = 0.536869, step = 16201 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 740.1\n",
      "INFO:tensorflow:loss = 0.48261, step = 16301 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 861.467\n",
      "INFO:tensorflow:loss = 0.611368, step = 16401 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 585.789\n",
      "INFO:tensorflow:loss = 0.446405, step = 16501 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 914.156\n",
      "INFO:tensorflow:loss = 0.502187, step = 16601 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 863.176\n",
      "INFO:tensorflow:loss = 0.537293, step = 16701 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.463\n",
      "INFO:tensorflow:loss = 0.48946, step = 16801 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.951\n",
      "INFO:tensorflow:loss = 0.669746, step = 16901 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 913.201\n",
      "INFO:tensorflow:loss = 0.438757, step = 17001 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.916\n",
      "INFO:tensorflow:loss = 0.669347, step = 17101 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 829.243\n",
      "INFO:tensorflow:loss = 0.373891, step = 17201 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 918.034\n",
      "INFO:tensorflow:loss = 0.425397, step = 17301 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 688.928\n",
      "INFO:tensorflow:loss = 0.409204, step = 17401 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.004\n",
      "INFO:tensorflow:loss = 0.529082, step = 17501 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 1004.31\n",
      "INFO:tensorflow:loss = 0.625195, step = 17601 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.752\n",
      "INFO:tensorflow:loss = 0.470826, step = 17701 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 753.836\n",
      "INFO:tensorflow:loss = 0.44317, step = 17801 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 960.824\n",
      "INFO:tensorflow:loss = 0.416412, step = 17901 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.493\n",
      "INFO:tensorflow:loss = 0.715811, step = 18001 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 815.511\n",
      "INFO:tensorflow:loss = 0.581576, step = 18101 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 916.782\n",
      "INFO:tensorflow:loss = 0.552794, step = 18201 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.004\n",
      "INFO:tensorflow:loss = 0.322738, step = 18301 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 691.55\n",
      "INFO:tensorflow:loss = 0.404912, step = 18401 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 974.862\n",
      "INFO:tensorflow:loss = 0.526873, step = 18501 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.05\n",
      "INFO:tensorflow:loss = 0.466027, step = 18601 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 734.772\n",
      "INFO:tensorflow:loss = 0.458171, step = 18701 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 892.739\n",
      "INFO:tensorflow:loss = 0.510078, step = 18801 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.804\n",
      "INFO:tensorflow:loss = 0.45136, step = 18901 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 715.527\n",
      "INFO:tensorflow:loss = 0.428257, step = 19001 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 1014.5\n",
      "INFO:tensorflow:loss = 0.484517, step = 19101 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 908.448\n",
      "INFO:tensorflow:loss = 0.382023, step = 19201 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.954\n",
      "INFO:tensorflow:loss = 0.387673, step = 19301 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.72\n",
      "INFO:tensorflow:loss = 0.604749, step = 19401 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 1004.3\n",
      "INFO:tensorflow:loss = 0.515726, step = 19501 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 921.009\n",
      "INFO:tensorflow:loss = 0.648311, step = 19601 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.457\n",
      "INFO:tensorflow:loss = 0.470446, step = 19701 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.481\n",
      "INFO:tensorflow:loss = 0.475956, step = 19801 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 994.319\n",
      "INFO:tensorflow:loss = 0.670806, step = 19901 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 956.27\n",
      "INFO:tensorflow:loss = 0.559192, step = 20001 (0.105 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20001 into C:\\Users\\WILLJD~1\\AppData\\Local\\Temp\\tmp49phijk0\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.559192.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_classifer.fit(X_train_prepared, np.ravel(y_train), steps = 20001, batch_size= 50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the TensorBoard chart below that is outlining the loss during the training, we can see that we found a minimal point around 14,000 steps. We will now run our model again with 14,200 steps in order to possibly obtain higher scores, although this may not be guaranteed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Capture.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\willjdsouza\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\WILLJD~1\\AppData\\Local\\Temp\\tmp49phijk0\\model.ckpt-20001\n",
      "INFO:tensorflow:Saving checkpoints for 20002 into C:\\Users\\WILLJD~1\\AppData\\Local\\Temp\\tmp49phijk0\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.446463, step = 20002\n",
      "INFO:tensorflow:global_step/sec: 920.308\n",
      "INFO:tensorflow:loss = 0.470152, step = 20102 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 979.57\n",
      "INFO:tensorflow:loss = 0.455371, step = 20202 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 834.877\n",
      "INFO:tensorflow:loss = 0.506634, step = 20302 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 942.727\n",
      "INFO:tensorflow:loss = 0.383684, step = 20402 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 846.864\n",
      "INFO:tensorflow:loss = 0.573334, step = 20502 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 984.313\n",
      "INFO:tensorflow:loss = 0.59681, step = 20602 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 921.003\n",
      "INFO:tensorflow:loss = 0.640611, step = 20702 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 899.891\n",
      "INFO:tensorflow:loss = 0.524835, step = 20802 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 836.077\n",
      "INFO:tensorflow:loss = 0.434968, step = 20902 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 984.516\n",
      "INFO:tensorflow:loss = 0.478958, step = 21002 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.868\n",
      "INFO:tensorflow:loss = 0.324073, step = 21102 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.868\n",
      "INFO:tensorflow:loss = 0.332747, step = 21202 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 862.724\n",
      "INFO:tensorflow:loss = 0.379816, step = 21302 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 885.223\n",
      "INFO:tensorflow:loss = 0.515303, step = 21402 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 942.561\n",
      "INFO:tensorflow:loss = 0.524815, step = 21502 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 872.307\n",
      "INFO:tensorflow:loss = 0.580185, step = 21602 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.949\n",
      "INFO:tensorflow:loss = 0.330419, step = 21702 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.757\n",
      "INFO:tensorflow:loss = 0.322106, step = 21802 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.19\n",
      "INFO:tensorflow:loss = 0.418776, step = 21902 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 880.757\n",
      "INFO:tensorflow:loss = 0.375485, step = 22002 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.641\n",
      "INFO:tensorflow:loss = 0.657286, step = 22102 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 979.698\n",
      "INFO:tensorflow:loss = 0.320704, step = 22202 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 975.023\n",
      "INFO:tensorflow:loss = 0.57477, step = 22302 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 850.582\n",
      "INFO:tensorflow:loss = 0.484105, step = 22402 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 960.848\n",
      "INFO:tensorflow:loss = 0.696111, step = 22502 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 872.129\n",
      "INFO:tensorflow:loss = 0.515668, step = 22602 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.192\n",
      "INFO:tensorflow:loss = 0.459953, step = 22702 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.567\n",
      "INFO:tensorflow:loss = 0.513358, step = 22802 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 983.106\n",
      "INFO:tensorflow:loss = 0.355847, step = 22902 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 942.731\n",
      "INFO:tensorflow:loss = 0.402927, step = 23002 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 965.5\n",
      "INFO:tensorflow:loss = 0.275911, step = 23102 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 824.905\n",
      "INFO:tensorflow:loss = 0.274586, step = 23202 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.949\n",
      "INFO:tensorflow:loss = 0.491049, step = 23302 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.956\n",
      "INFO:tensorflow:loss = 0.395039, step = 23402 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 867.621\n",
      "INFO:tensorflow:loss = 0.419539, step = 23502 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 873.466\n",
      "INFO:tensorflow:loss = 0.54395, step = 23602 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.664\n",
      "INFO:tensorflow:loss = 0.380667, step = 23702 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 940.062\n",
      "INFO:tensorflow:loss = 0.586416, step = 23802 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 944.91\n",
      "INFO:tensorflow:loss = 0.455372, step = 23902 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 963.03\n",
      "INFO:tensorflow:loss = 0.541288, step = 24002 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 974.918\n",
      "INFO:tensorflow:loss = 0.446023, step = 24102 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.631\n",
      "INFO:tensorflow:loss = 0.658124, step = 24202 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 974.921\n",
      "INFO:tensorflow:loss = 0.376811, step = 24302 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.768\n",
      "INFO:tensorflow:loss = 0.58318, step = 24402 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 948.719\n",
      "INFO:tensorflow:loss = 0.521824, step = 24502 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 960.859\n",
      "INFO:tensorflow:loss = 0.306717, step = 24602 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 864.119\n",
      "INFO:tensorflow:loss = 0.471423, step = 24702 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 880.44\n",
      "INFO:tensorflow:loss = 0.567529, step = 24802 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 987.532\n",
      "INFO:tensorflow:loss = 0.463843, step = 24902 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 879.16\n",
      "INFO:tensorflow:loss = 0.381134, step = 25002 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.757\n",
      "INFO:tensorflow:loss = 0.5733, step = 25102 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 957.855\n",
      "INFO:tensorflow:loss = 0.562431, step = 25202 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 893.083\n",
      "INFO:tensorflow:loss = 0.460426, step = 25302 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 938.3\n",
      "INFO:tensorflow:loss = 0.578706, step = 25402 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 737.9\n",
      "INFO:tensorflow:loss = 0.312992, step = 25502 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.154\n",
      "INFO:tensorflow:loss = 0.55246, step = 25602 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.52\n",
      "INFO:tensorflow:loss = 0.469054, step = 25702 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.981\n",
      "INFO:tensorflow:loss = 0.443798, step = 25802 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.744\n",
      "INFO:tensorflow:loss = 0.289915, step = 25902 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 979.694\n",
      "INFO:tensorflow:loss = 0.37962, step = 26002 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 956.261\n",
      "INFO:tensorflow:loss = 0.338583, step = 26102 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.954\n",
      "INFO:tensorflow:loss = 0.3719, step = 26202 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.192\n",
      "INFO:tensorflow:loss = 0.232176, step = 26302 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.324\n",
      "INFO:tensorflow:loss = 0.347456, step = 26402 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 949.73\n",
      "INFO:tensorflow:loss = 0.252364, step = 26502 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 947.189\n",
      "INFO:tensorflow:loss = 0.655138, step = 26602 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 951.713\n",
      "INFO:tensorflow:loss = 0.310743, step = 26702 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.779\n",
      "INFO:tensorflow:loss = 0.705155, step = 26802 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 691.428\n",
      "INFO:tensorflow:loss = 0.418604, step = 26902 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 958.955\n",
      "INFO:tensorflow:loss = 0.418852, step = 27002 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.217\n",
      "INFO:tensorflow:loss = 0.535216, step = 27102 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 713.786\n",
      "INFO:tensorflow:loss = 0.283542, step = 27202 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.169\n",
      "INFO:tensorflow:loss = 0.306678, step = 27302 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.489441, step = 27402 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 796.244\n",
      "INFO:tensorflow:loss = 0.374534, step = 27502 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 622.327\n",
      "INFO:tensorflow:loss = 0.387807, step = 27602 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.043\n",
      "INFO:tensorflow:loss = 0.527893, step = 27702 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 679.791\n",
      "INFO:tensorflow:loss = 0.315891, step = 27802 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 846.853\n",
      "INFO:tensorflow:loss = 0.377831, step = 27902 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 925.182\n",
      "INFO:tensorflow:loss = 0.414141, step = 28002 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 858.574\n",
      "INFO:tensorflow:loss = 0.511438, step = 28102 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 936.975\n",
      "INFO:tensorflow:loss = 0.408973, step = 28202 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.858\n",
      "INFO:tensorflow:loss = 0.322479, step = 28302 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.374\n",
      "INFO:tensorflow:loss = 0.441597, step = 28402 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.944\n",
      "INFO:tensorflow:loss = 0.400772, step = 28502 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 916.475\n",
      "INFO:tensorflow:loss = 0.470217, step = 28602 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.567\n",
      "INFO:tensorflow:loss = 0.403882, step = 28702 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 857.759\n",
      "INFO:tensorflow:loss = 0.531841, step = 28802 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.027\n",
      "INFO:tensorflow:loss = 0.274891, step = 28902 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.14\n",
      "INFO:tensorflow:loss = 0.433939, step = 29002 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 933.784\n",
      "INFO:tensorflow:loss = 0.402746, step = 29102 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 585.952\n",
      "INFO:tensorflow:loss = 0.421692, step = 29202 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 567.782\n",
      "INFO:tensorflow:loss = 0.512064, step = 29302 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.945\n",
      "INFO:tensorflow:loss = 0.436816, step = 29402 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.12\n",
      "INFO:tensorflow:loss = 0.542016, step = 29502 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.061\n",
      "INFO:tensorflow:loss = 0.602055, step = 29602 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 973.091\n",
      "INFO:tensorflow:loss = 0.488278, step = 29702 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 737.494\n",
      "INFO:tensorflow:loss = 0.473258, step = 29802 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.091\n",
      "INFO:tensorflow:loss = 0.438299, step = 29902 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.749\n",
      "INFO:tensorflow:loss = 0.243693, step = 30002 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 944.106\n",
      "INFO:tensorflow:loss = 0.543338, step = 30102 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.831\n",
      "INFO:tensorflow:loss = 0.298961, step = 30202 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.369\n",
      "INFO:tensorflow:loss = 0.275499, step = 30302 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 920.451\n",
      "INFO:tensorflow:loss = 0.342916, step = 30402 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 569.393\n",
      "INFO:tensorflow:loss = 0.322309, step = 30502 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.156\n",
      "INFO:tensorflow:loss = 0.533388, step = 30602 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.772\n",
      "INFO:tensorflow:loss = 0.406491, step = 30702 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 612.549\n",
      "INFO:tensorflow:loss = 0.448682, step = 30802 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.813\n",
      "INFO:tensorflow:loss = 0.379587, step = 30902 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 927.917\n",
      "INFO:tensorflow:loss = 0.447293, step = 31002 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 836.167\n",
      "INFO:tensorflow:loss = 0.345345, step = 31102 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.847\n",
      "INFO:tensorflow:loss = 0.344565, step = 31202 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 865.194\n",
      "INFO:tensorflow:loss = 0.450539, step = 31302 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 879.171\n",
      "INFO:tensorflow:loss = 0.439667, step = 31402 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 856.535\n",
      "INFO:tensorflow:loss = 0.321005, step = 31502 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 929.984\n",
      "INFO:tensorflow:loss = 0.430588, step = 31602 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 959.639\n",
      "INFO:tensorflow:loss = 0.524822, step = 31702 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 950.408\n",
      "INFO:tensorflow:loss = 0.372796, step = 31802 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 948.684\n",
      "INFO:tensorflow:loss = 0.337663, step = 31902 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.326\n",
      "INFO:tensorflow:loss = 0.420351, step = 32002 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 778.545\n",
      "INFO:tensorflow:loss = 0.430829, step = 32102 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 913.416\n",
      "INFO:tensorflow:loss = 0.465157, step = 32202 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.069\n",
      "INFO:tensorflow:loss = 0.719365, step = 32302 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.517\n",
      "INFO:tensorflow:loss = 0.38362, step = 32402 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 547.759\n",
      "INFO:tensorflow:loss = 0.387984, step = 32502 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 836.228\n",
      "INFO:tensorflow:loss = 0.433447, step = 32602 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 850.458\n",
      "INFO:tensorflow:loss = 0.557068, step = 32702 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 958.4\n",
      "INFO:tensorflow:loss = 0.398966, step = 32802 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 872.739\n",
      "INFO:tensorflow:loss = 0.405452, step = 32902 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.582\n",
      "INFO:tensorflow:loss = 0.480382, step = 33002 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 860.926\n",
      "INFO:tensorflow:loss = 0.416932, step = 33102 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 865.187\n",
      "INFO:tensorflow:loss = 0.39123, step = 33202 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.706\n",
      "INFO:tensorflow:loss = 0.600897, step = 33302 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.499\n",
      "INFO:tensorflow:loss = 0.482688, step = 33402 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 953.446\n",
      "INFO:tensorflow:loss = 0.538815, step = 33502 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 956.704\n",
      "INFO:tensorflow:loss = 0.594677, step = 33602 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 960.853\n",
      "INFO:tensorflow:loss = 0.442468, step = 33702 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 686.798\n",
      "INFO:tensorflow:loss = 0.474556, step = 33802 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.518\n",
      "INFO:tensorflow:loss = 0.632617, step = 33902 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.996\n",
      "INFO:tensorflow:loss = 0.483177, step = 34002 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 938.098\n",
      "INFO:tensorflow:loss = 0.284187, step = 34102 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 977.734\n",
      "INFO:tensorflow:loss = 0.233259, step = 34202 (0.102 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34202 into C:\\Users\\WILLJD~1\\AppData\\Local\\Temp\\tmp49phijk0\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.233259.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\WILLJD~1\\AppData\\Local\\Temp\\tmp49phijk0\\model.ckpt-34202\n"
     ]
    }
   ],
   "source": [
    "start_dnn = timeit.default_timer()\n",
    "dnn_classifer.fit(X_train_prepared, np.ravel(y_train), steps = 14201, batch_size= 50) \n",
    "dnn_predicted = dnn_classifer.predict(X_train_prepared)\n",
    "stop_dnn = timeit.default_timer()\n",
    "dnn_predictions = dnn_predicted['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Accuracy Score: 0.822720730451\n",
      "DNN Precision Score: 0.834330891551\n"
     ]
    }
   ],
   "source": [
    "dnn_accuracy = accuracy_score(dnn_predictions, np.ravel(y_train))\n",
    "dnn_precision = precision_score(dnn_predictions, np.ravel(y_train), average=\"weighted\")\n",
    "print(\"DNN Accuracy Score:\", dnn_accuracy)\n",
    "print(\"DNN Precision Score:\", dnn_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not look like our model performed better than the Random Forest Classifer or even the KNN classifier. Although, it was rocket fast..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are a few visualization that comapre all the models above comparing:\n",
    "\n",
    "1) SGD Classifier\n",
    "\n",
    "2) GNB CLassifier\n",
    "\n",
    "3) Random Forest Classifier\n",
    "\n",
    "4) KNN Classifier\n",
    "\n",
    "5) Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEdCAYAAAAfA1CsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktSJgSFJ6sTAkCR1YmBIkjr5XyhdpokZi9LMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f78fd46be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEdCAYAAAAfA1CsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwjAzsyL/B2t8ZSl65e95AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f7913a1668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEdCAYAAAAikTHKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f791062be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model =['SGD','GNB','RFC','KNN','DNN']\n",
    "pos = np.arange(len(model))\n",
    "accuracy_scores = [sgd_accuracy, gnb_accuracy, rfc_accuracy, knn_accuracy, dnn_accuracy]\n",
    "precision_scores = [sgd_precision, gnb_precision, rfc_precision, knn_precision, dnn_precision]\n",
    "time_to_run = [stop_sgd - start_sgd, stop_gnb - start_gnb, stop_rfc - start_rfc, stop_knn - start_knn, stop_dnn - start_dnn]\n",
    "\n",
    "\n",
    "plt.bar(pos,accuracy_scores, color = \"sandybrown\")\n",
    "plt.xticks(pos, model)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Accuracy Scores')\n",
    "plt.show()\n",
    "\n",
    "plt.bar(pos,precision_scores, color = \"cadetblue\")\n",
    "plt.xticks(pos, model)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Precision - Weighted - Scores')\n",
    "plt.show()\n",
    "\n",
    "plt.bar(pos,time_to_run, color = \"coral\")\n",
    "plt.xticks(pos, model)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Seconds')\n",
    "plt.title('Time to Train Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest scores obtained was the Random Forest Classifier in all categories except the time taken to train & make prediction. Although the DNN beat it in this category, the Random Forest Classifier will be chosen as the go-to model because of its high scores and minimal run time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test Predicitions with RFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we could spend more time hypertuning the parameters, with such high scores there is almost absolutely no need to. The default model performs exceptionally well on the training set. We can go ahead and skip to now making predicitiosn on our test set.\n",
    "\n",
    "The predicitions are pretty close to the same error we saw with the trainnig set, the classification model works well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Accuracy Test Score: 0.945044448078\n",
      "RFC Precision Test Score: 0.946215943395\n",
      "RFC Recall Test Score: 0.945044448078\n",
      "RFC F1 Test Score: 0.945379565171\n"
     ]
    }
   ],
   "source": [
    "rfc_test_predicted = rfc.predict(X_test_prepared)\n",
    "rfc_test_accuracy = accuracy_score(rfc_test_predicted, np.ravel(y_test))\n",
    "rfc_test_precision = precision_score(rfc_test_predicted, np.ravel(y_test), average = 'weighted')\n",
    "rfc_test_recall = recall_score(rfc_test_predicted, np.ravel(y_test), average = 'weighted')\n",
    "rfc_test_f1 = f1_score(rfc_test_predicted, np.ravel(y_test), average = 'weighted')\n",
    "\n",
    "print(\"RFC Accuracy Test Score:\", rfc_test_accuracy)\n",
    "print(\"RFC Precision Test Score:\", rfc_test_precision)\n",
    "print(\"RFC Recall Test Score:\", rfc_test_recall)\n",
    "print(\"RFC F1 Test Score:\", rfc_test_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
